{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFF Demo Pipeline: FIGRL class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demo for the python implementation of the FIGRL algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two global parameters need to be defined for this pipeline. The embedding size of figrl's embeddings, and the 'intermediate_dimension'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters:\n",
    "embedding_size = 40\n",
    "intermediate_dimension = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the demo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"demo_ccf.csv\")\n",
    "df = df.set_index(df.index+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The credit card dataset will be split into two parts the training & inductive datasets. The first 60% of the transactions will be the training transactions to train de algorithm and then the resting 40% will be used as inductive set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = round(0.6*len(df))\n",
    "train_data = df.head(cutoff)\n",
    "inductive_data = df.tail(len(df)-cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of fraud for the train data is:\n",
      " 0    482\n",
      "1    164\n",
      "Name: fraud_label, dtype: int64\n",
      "The distribution of fraud for the inductive data is:\n",
      " 0    327\n",
      "1    103\n",
      "Name: fraud_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The distribution of fraud for the train data is:\\n', train_data['fraud_label'].value_counts())\n",
    "print('The distribution of fraud for the inductive data is:\\n', inductive_data['fraud_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct the Graph Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A networkx graph is constructed with edit, user and webpage nodes. Creating a three partite graph. The FI-GRL framework derives embeddings starting from an adjacency matrix that it constructs using the graph's edgelist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {\"transaction\":train_data.index, \"client\":train_data.client_node, \"merchant\":train_data.merchant_node}\n",
    "edges = [zip(train_data.client_node, train_data.index),zip(train_data.merchant_node, train_data.index)]\n",
    "g_nx = nx.Graph()\n",
    "for key, values in nodes.items():\n",
    "            g_nx.add_nodes_from(values, ntype=key)\n",
    "for edge in edges:\n",
    "            g_nx.add_edges_from(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train FIGRL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FI-GRL, a fast inductive graph representation framework is trained using the aforeconstructed graph. This algorithm is implemented in a python class. First, we instantiate the FI-GRL class with the intermediate dimension of the matrix between the input graph and the embedding space, in addition to the size of final dimension (embedding space). FI-GRL's train step returns the embeddings for the train transaction nodes.\n",
    "\n",
    "Currently there are three versions of figrl in python: FIGRL_Original, FIGRL_expanding_S, and FIGRL\n",
    "The latter is advised due to being the fastest and least memory intensive one of the three.\n",
    "\n",
    "Import of the wanted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FIGRL import FIGRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "figrl = FIGRL(embedding_size, intermediate_dimension)\n",
    "figrl_train_emb = figrl.fit(g_nx)\n",
    "figrl_train_emb = figrl_train_emb.loc[train_data.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inductive Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "inductive_graph_data = pd.concat((train_data,inductive_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph containing the inductive data and training data is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {\"transaction\":inductive_graph_data.index, \"client\":inductive_graph_data.client_node, \"merchant\":inductive_graph_data.merchant_node}\n",
    "edges = [zip(inductive_graph_data.client_node, inductive_graph_data.index),zip(inductive_graph_data.merchant_node, inductive_graph_data.index)]\n",
    "graph_full = nx.Graph()\n",
    "\n",
    "for key, values in nodes.items():\n",
    "            graph_full.add_nodes_from(values, ntype=key)\n",
    "for edge in edges:\n",
    "            graph_full.add_edges_from(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inductive prediction function of FIGRL: The full grpah is given, the inductive data, a list of the columns of neighboring nodes of the inductive data, the maximum id number of all nodes, and finally the index number of the inductive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figrl_inductive_emb = figrl.predict(graph_full, inductive_data, [inductive_data.client_node,inductive_data.merchant_node], max(inductive_graph_data.merchant_node), inductive_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_data['fraud_label']\n",
    "add_additional_data = True\n",
    "if add_additional_data is True:\n",
    "    train_emb = pd.merge(figrl_train_emb, train_data.loc[figrl_train_emb.index].drop('fraud_label', axis=1), left_index=True, right_index=True)\n",
    "    inductive_emb = pd.merge(figrl_inductive_emb, inductive_data.loc[figrl_inductive_emb.index].drop('fraud_label', axis=1), left_index=True, right_index=True)\n",
    "\n",
    "    baseline_train = train_data.drop('fraud_label', axis=1)\n",
    "    baseline_inductive = inductive_data.drop('fraud_label', axis=1)\n",
    "\n",
    "    classifier.fit(baseline_train, train_labels)\n",
    "    baseline_predictions = classifier.predict_proba(baseline_inductive)\n",
    "    \n",
    "classifier.fit(train_emb, train_labels)\n",
    "predictions = classifier.predict_proba(inductive_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score for  FI-GRL+features  configuration XGBoost: 0.8246865220\n",
      "Average precision-recall score for  Baseline  configuration XGBoost: 0.8503629197\n"
     ]
    }
   ],
   "source": [
    "from components.Evaluation import Evaluation\n",
    "inductive_labels = df.loc[inductive_emb.index]['fraud_label']\n",
    "\n",
    "figrl_evaluation = Evaluation(predictions, inductive_labels, \"FI-GRL+features\") \n",
    "figrl_evaluation.pr_curve()\n",
    "\n",
    "if add_additional_data is True:\n",
    "    baseline_evaluation = Evaluation(baseline_predictions, inductive_labels, \"Baseline\")\n",
    "    baseline_evaluation.pr_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
